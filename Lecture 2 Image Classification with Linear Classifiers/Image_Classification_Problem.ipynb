{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5bv6XEUCipf",
        "outputId": "1c4eecef-b68c-4d84-899b-5044a6cfe5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando 0/100\n",
            "accuracy: 0.240000\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Librerías necesarias\n",
        "import numpy as np\n",
        "import pickle, tarfile, os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Paso 2: Cargar CIFAR-10\n",
        "def load_CIFAR10(path):\n",
        "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "    if not os.path.exists(path): os.makedirs(path)\n",
        "    tgz_path = os.path.join(path, 'cifar-10-python.tar.gz')\n",
        "    if not os.path.exists(tgz_path):\n",
        "        print(\"Descargando CIFAR-10...\")\n",
        "        urlretrieve(url, tgz_path)\n",
        "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
        "        tar.extractall(path)\n",
        "    def load_batch(file):\n",
        "        with open(file, 'rb') as f:\n",
        "            d = pickle.load(f, encoding='bytes')\n",
        "            return d[b'data'], d[b'labels']\n",
        "    Xs, Ys = [], []\n",
        "    for i in range(1, 6):\n",
        "        X, Y = load_batch(os.path.join(path, 'cifar-10-batches-py', f'data_batch_{i}'))\n",
        "        Xs.append(X); Ys.append(Y)\n",
        "    Xtr = np.concatenate(Xs); Ytr = np.concatenate(Ys)\n",
        "    Xte, Yte = load_batch(os.path.join(path, 'cifar-10-batches-py', 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, np.array(Yte)\n",
        "\n",
        "# Paso 3: Implementar Nearest Neighbor\n",
        "class NearestNeighbor:\n",
        "    def train(self, X, y): self.Xtr, self.ytr = X, y\n",
        "    def predict(self, X):\n",
        "        Ypred = np.zeros(X.shape[0], dtype=self.ytr.dtype)\n",
        "        for i in range(X.shape[0]):\n",
        "            dists = np.sum(np.abs(self.Xtr - X[i, :]), axis=1)\n",
        "            Ypred[i] = self.ytr[np.argmin(dists)]\n",
        "            if i % 100 == 0: print(f'Procesando {i}/{X.shape[0]}')\n",
        "        return Ypred\n",
        "\n",
        "# Paso 4: Ejecutar todo\n",
        "Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/')\n",
        "Xtr_rows = Xtr.reshape(Xtr.shape[0], -1)[:1000]  # usar solo 1000 imágenes para rapidez\n",
        "Ytr = Ytr[:1000]\n",
        "Xte_rows = Xte.reshape(Xte.shape[0], -1)[:100]   # usar solo 100 imágenes de prueba\n",
        "Yte = Yte[:100]\n",
        "\n",
        "nn = NearestNeighbor()\n",
        "nn.train(Xtr_rows, Ytr)\n",
        "Yte_predict = nn.predict(Xte_rows)\n",
        "\n",
        "print('accuracy: %f' % (np.mean(Yte_predict == Yte)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Librerías necesarias\n",
        "import numpy as np\n",
        "import pickle, tarfile, os\n",
        "from urllib.request import urlretrieve\n",
        "from collections import Counter\n",
        "\n",
        "# Paso 2: Cargar CIFAR-10\n",
        "def load_CIFAR10(path):\n",
        "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "    if not os.path.exists(path): os.makedirs(path)\n",
        "    tgz_path = os.path.join(path, 'cifar-10-python.tar.gz')\n",
        "    if not os.path.exists(tgz_path):\n",
        "        print(\"Descargando CIFAR-10...\")\n",
        "        urlretrieve(url, tgz_path)\n",
        "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
        "        tar.extractall(path)\n",
        "    def load_batch(file):\n",
        "        with open(file, 'rb') as f:\n",
        "            d = pickle.load(f, encoding='bytes')\n",
        "            return d[b'data'], d[b'labels']\n",
        "    Xs, Ys = [], []\n",
        "    for i in range(1, 6):\n",
        "        X, Y = load_batch(os.path.join(path, 'cifar-10-batches-py', f'data_batch_{i}'))\n",
        "        Xs.append(X); Ys.append(Y)\n",
        "    Xtr = np.concatenate(Xs); Ytr = np.concatenate(Ys)\n",
        "    Xte, Yte = load_batch(os.path.join(path, 'cifar-10-batches-py', 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, np.array(Yte)\n",
        "\n",
        "# Paso 3: Implementar Nearest Neighbor mejorado (L2 + k-NN)\n",
        "class NearestNeighbor:\n",
        "    def train(self, X, y):\n",
        "        self.Xtr = X\n",
        "        self.ytr = y\n",
        "\n",
        "    def predict(self, X, k=3):\n",
        "        Ypred = np.zeros(X.shape[0], dtype=self.ytr.dtype)\n",
        "        for i in range(X.shape[0]):\n",
        "            dists = np.sqrt(np.sum((self.Xtr - X[i, :]) ** 2, axis=1))  # L2\n",
        "            k_indices = np.argsort(dists)[:k]\n",
        "            k_labels = self.ytr[k_indices]\n",
        "            Ypred[i] = Counter(k_labels).most_common(1)[0][0]\n",
        "            if i % 50 == 0:\n",
        "                print(f'Procesando {i}/{X.shape[0]}')\n",
        "        return Ypred\n",
        "\n",
        "# Paso 4: Ejecutar todo\n",
        "Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/')\n",
        "Xtr_rows = Xtr.reshape(Xtr.shape[0], -1)[:5000]\n",
        "Ytr = Ytr[:5000]\n",
        "Xte_rows = Xte.reshape(Xte.shape[0], -1)[:500]\n",
        "Yte = Yte[:500]\n",
        "\n",
        "# Paso 5: Normalizar los datos (media 0, varianza 1)\n",
        "mean = np.mean(Xtr_rows, axis=0)\n",
        "std = np.std(Xtr_rows, axis=0)\n",
        "Xtr_rows = (Xtr_rows - mean) / (std + 1e-7)\n",
        "Xte_rows = (Xte_rows - mean) / (std + 1e-7)\n",
        "\n",
        "# Paso 6: Entrenar y predecir\n",
        "nn = NearestNeighbor()\n",
        "nn.train(Xtr_rows, Ytr)\n",
        "Yte_predict = nn.predict(Xte_rows, k=3)\n",
        "\n",
        "# Paso 7: Calcular precisión\n",
        "accuracy = np.mean(Yte_predict == Yte)\n",
        "print(f'Precisión con k-NN (k=3) y L2: {accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI4i9QA_DmLJ",
        "outputId": "26bd1bcb-ebf3-45ab-aa79-4dbdf1e9fbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando 0/500\n",
            "Procesando 50/500\n",
            "Procesando 100/500\n",
            "Procesando 150/500\n",
            "Procesando 200/500\n",
            "Procesando 250/500\n",
            "Procesando 300/500\n",
            "Procesando 350/500\n",
            "Procesando 400/500\n",
            "Procesando 450/500\n",
            "Precisión con k-NN (k=3) y L2: 0.2620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Librerías necesarias\n",
        "import numpy as np\n",
        "import pickle, tarfile, os\n",
        "from urllib.request import urlretrieve\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Paso 2: Cargar CIFAR-10\n",
        "def load_CIFAR10(path):\n",
        "    url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "    if not os.path.exists(path): os.makedirs(path)\n",
        "    tgz_path = os.path.join(path, 'cifar-10-python.tar.gz')\n",
        "    if not os.path.exists(tgz_path):\n",
        "        print(\"Descargando CIFAR-10...\")\n",
        "        urlretrieve(url, tgz_path)\n",
        "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
        "        tar.extractall(path)\n",
        "    def load_batch(file):\n",
        "        with open(file, 'rb') as f:\n",
        "            d = pickle.load(f, encoding='bytes')\n",
        "            return d[b'data'], d[b'labels']\n",
        "    Xs, Ys = [], []\n",
        "    for i in range(1, 6):\n",
        "        X, Y = load_batch(os.path.join(path, 'cifar-10-batches-py', f'data_batch_{i}'))\n",
        "        Xs.append(X); Ys.append(Y)\n",
        "    Xtr = np.concatenate(Xs); Ytr = np.concatenate(Ys)\n",
        "    Xte, Yte = load_batch(os.path.join(path, 'cifar-10-batches-py', 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, np.array(Yte)\n",
        "\n",
        "# Paso 3: Cargar datos y preprocesar\n",
        "print(\"Cargando CIFAR-10...\")\n",
        "Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/')\n",
        "\n",
        "# Reducimos el tamaño para acelerar ejecución (puedes aumentar si deseas)\n",
        "Xtr = Xtr[:10000]\n",
        "Ytr = Ytr[:10000]\n",
        "Xte = Xte[:1000]\n",
        "Yte = Yte[:1000]\n",
        "\n",
        "# Aplanar imágenes\n",
        "Xtr_rows = Xtr.reshape(Xtr.shape[0], -1)\n",
        "Xte_rows = Xte.reshape(Xte.shape[0], -1)\n",
        "\n",
        "# Normalización\n",
        "mean = np.mean(Xtr_rows, axis=0)\n",
        "std = np.std(Xtr_rows, axis=0)\n",
        "Xtr_rows = (Xtr_rows - mean) / (std + 1e-7)\n",
        "Xte_rows = (Xte_rows - mean) / (std + 1e-7)\n",
        "\n",
        "# Reducción opcional de dimensión con PCA (puedes desactivarla si quieres)\n",
        "print(\"Aplicando PCA...\")\n",
        "pca = PCA(n_components=200)\n",
        "Xtr_pca = pca.fit_transform(Xtr_rows)\n",
        "Xte_pca = pca.transform(Xte_rows)\n",
        "\n",
        "# Paso 4: Entrenar SVM\n",
        "print(\"Entrenando SVM...\")\n",
        "clf = SVC(kernel='rbf', C=10, gamma='scale')  # Puedes ajustar C y gamma\n",
        "clf.fit(Xtr_pca, Ytr)\n",
        "\n",
        "# Paso 5: Predecir y evaluar\n",
        "print(\"Prediciendo...\")\n",
        "Ypred = clf.predict(Xte_pca)\n",
        "accuracy = accuracy_score(Yte, Ypred)\n",
        "\n",
        "print(f'Precisión final con SVM + PCA: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkzsnmQUEIsz",
        "outputId": "44e97775-4164-4b4b-dafc-191f0fa97bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando CIFAR-10...\n",
            "Aplicando PCA...\n",
            "Entrenando SVM...\n",
            "Prediciendo...\n",
            "Precisión final con SVM + PCA: 0.4740\n"
          ]
        }
      ]
    }
  ]
}